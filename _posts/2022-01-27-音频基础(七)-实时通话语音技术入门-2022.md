---
layout:     post
title:      "音频基础(七)-实时通话语音技术入门, 2022"
subtitle:   "欢迎使用"
date:       2022-01-27 19:04:20
author:     "Ruer"
header-img: "img/bg/hello_world.jpg"
catalog: true
tags:
    - Audio
---

## 概念模型

网络语音通话通常是双向的，就模型层面来说，这个双向是对称的。为了简单起见，讨论一个方向的通道就可以了。一方说话，另一方听到声音。看似简单，其背后的流程却是相当复杂的。将其经过的各个主要环节简化成下图所示的概念模型：

![1](/img/Audio/概念模型.png)

这是一个最基础的模型，由五个重要的环节构成：采集、编码、传送、解码、播放。

#### 采集

采集指的是从麦克风采集音频数据，即声音样本转换成数字信号。其涉及的几个重要的参数：采样频率、采样位数、声道数。

简单来说，采样频率就是在 1s 内进行采集动作的次数。采样位数就是每次采集动作得到的数据长度。

`一个音频帧的大小 = ( 采样频率 * 采样位数 * 声道数 * 时间 ) / 8`

通常一个采样帧的时长为 10ms，即每 10ms 的数据构成一个音频帧。假设：采样率 16K、采样位数 16bit、声道数 1，那么一个 10ms 的音频帧的大小为：

`( 16000 * 16 * 1 * 0.01 ) / 8 = 320 Byte`

#### 编码

假设将采集到的音频帧不经过编码直接发送，那么可以计算其所需要的带宽是 256kb/s，这是个很大的带宽占用。

所以实际的语音应用中，编码这个环节是不可缺少的。目前有很多常用的语音编码技术，像 G.729、iLBC、AAC、SPEEX 等等。

#### 传送

当一个音频帧完成编码后，即可通过网络发送给通话的对方。对于语音对话这样的 Realtime 应用，低延迟和平稳是非常重要的，这就要求网络传输非常顺畅。

#### 解码

当对方接收到编码帧后，会对其进行解码，以恢复为可供声卡直接播放的数据。

#### 播放

完成解码后，即可将得到的音频帧提交给声卡进行播放。

## 实际应用中的难点及解决方案

如果仅仅依靠上述的技术就能实现一个效果良好的应用于广域网上的语音对话系统，那就没什么必要撰写此文了。正是有很多现实的因素为上述的概念模型引入了众多挑战，是的网络语音系统的实现不是那么简单，其涉及到很多专业技术。

这些挑战大多已经有了成熟的解决方案。首先，为`效果良好`的语音对话系统下个定义，应该达到如下几点：

> 1. 低延迟。只有低延迟，才能让通话的双方有很强的 Realtime 的感觉。这个主要取决于网络速度和通话双方的物理距离，通过软件优化的可能性很小。
> 2. 背景噪音小。
> 3. 声音流畅、没有卡、停顿的感觉。
> 4. 没有回音。

下面逐个说说实际网络语音对话系统中额外用到的技术。

#### 回音消除 AEC

当使用外放功能时，扬声器播放的声音会被麦克风再次采集，传回给对方。这样对方就听到了自己的回音。所以实际应用中，回音消除的功能时必须的。

在得到采集的音频帧后，到编码之前的这个间隙，是回音消除模块工作的时机。

![2](/img/Audio/回音消除.png)

回音消除模块依据刚播放的音频帧，在采集的音频帧中做一些类似抵消的运算，从而将回声从采集帧中清除掉。这个过程是相当复杂的，而且其还与所处的房间大小、所处房间位置有关。因为这些信息决定了声波反射的时长。智能的回音消除模块，能动态调整内部参数，以最佳适应当前的环境。

#### 噪声抑制 DENOISE

噪声抑制又被称为降噪处理，是根据语音数据的特点，将属于背景噪音的部分识别出来，并从音频帧中过滤掉。有很多编码器都内置了该功能。

#### 抖动缓冲区 JitterBuffer

抖动缓冲区用于解决网络抖动的问题。所谓网络抖动，就是网络延迟一会大一会小，在这种情况下，即使发送方是定时发送数据包的，接收方有时一个周期内一个包都接收不到，有时一个周期内接收到好几个包。如此，导致接收方听到的声音就是一卡一卡的。

JitterBuffer 工作于解码器之后，语音播放之前的环节。即语音解码完成后，将解码帧放入 JitterBuffer，声卡的播放回调到来时，从 JitterBuffer 中取出最老的一帧进行播放。

![3](/img/Audio/抖动缓冲区.png)

JitterBuffer 的缓冲深度取决于网络抖动的程度，网络抖动越大，缓冲深度越大，播放音频的延迟就越大。所以 JitterBuffer 是利用了较高的延迟来换取声音的流畅播放的，因为相比声音一卡一卡来说，稍大一点的延迟但更流畅的效果，其主观体验更好。

当然，JitterBuffer 的缓冲深度不是一直不变的，而是根据网络抖动程度的变化来动态调整的。当网络恢复到非常平稳通畅时，缓冲深度会非常小，这样因为 JitterBuffer 而增加的播放延迟就可以忽略不计了。

#### 静音检测 VAD

在语音对话中，要是一方没有说话时，不产生流量就好了。静音检测就是用于这个目的。静音检测通常也集成在编码模块中。静音检测算法结合前面的噪声抑制算法，可以识别出当前是否有语音输入，如果没有语音输入，就可以编码输出一个特殊的编码帧。

特别是在多人视频会议中，通常只有一个人在发言，这种情况下，利用静音检测技术而节省的带宽还是非常可观的。

#### 混音算法

在多人语音聊天时，需要同时播放来自于多个人的语音数据，而声卡播放的缓冲区只有一个。所以需要将多路语音混合成一路，这就是混音算法要做的事情。即使可以想办法绕开混音而让多路声音同时播放，那么回音消除最多只能消除多路声音中的某一路。

混音可以在客户端进行，也可以在服务端进行。如果使用了 P2P 通道，那么混音只能在客户端进行了。如果是在客户端混音，混音通常放在播放前的最后一个环节。

综合上面的概念模型以及实现中用到的网络语音技术，下面给出一个完整的模型图：

![4](/img/Audio/混音算法.png)